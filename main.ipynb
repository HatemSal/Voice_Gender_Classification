{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def aggregate_2d(feature):\n",
    "    return np.concatenate([\n",
    "        np.mean(feature, axis=1),  \n",
    "        np.std(feature, axis=1),   \n",
    "        np.max(feature, axis=1),    \n",
    "        np.min(feature, axis=1),    \n",
    "    ])\n",
    "def aggregate(feature):\n",
    "    return np.array([\n",
    "        np.mean(feature),\n",
    "        np.std(feature),\n",
    "        np.median(feature),\n",
    "        np.max(feature),\n",
    "        np.min(feature),\n",
    "        np.percentile(feature, 25),  \n",
    "        np.percentile(feature, 75)\n",
    "    ])\n",
    "def preprocess_wav(wav_file_path,sample_rate=16000):\n",
    "    audio, sr = librosa.load(wav_file_path, sr=sample_rate)\n",
    "    audio = librosa.effects.preemphasis(audio, coef=0.97)\n",
    "    \n",
    "    spectrogram = np.abs(librosa.stft(audio, n_fft=1024, hop_length=256))**2\n",
    "    \n",
    "    centroid = librosa.feature.spectral_centroid(S=spectrogram, sr=sr)\n",
    "    centroid = aggregate(centroid)\n",
    "   \n",
    "    contrast = librosa.feature.spectral_contrast(S=spectrogram, sr=sr)\n",
    "    contrast = aggregate_2d(contrast)\n",
    "    \n",
    "    flatness = librosa.feature.spectral_flatness(S=spectrogram)\n",
    "    flatness = aggregate(flatness)\n",
    "    \n",
    "    rolloff = librosa.feature.spectral_rolloff(S=spectrogram, sr=sr)\n",
    "    rolloff = aggregate(rolloff)\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(S=librosa.power_to_db(spectrogram), n_mfcc=13)\n",
    "    mfccs = aggregate_2d(mfccs)\n",
    "    \n",
    "    features = np.concatenate([mfccs, centroid, contrast, flatness, rolloff],axis=0)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101,)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preprocess_wav('Dataset/males/0.wav')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderDataset(Dataset):\n",
    "    def __init__(self, root,sample_rate=16000):\n",
    "        self.root = root\n",
    "        self.sample_rate = sample_rate\n",
    "        self.audio_files = list(self.root.glob('*/*.wav'))\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.audio_files)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        audio_file = self.audio_files[idx]\n",
    "        label = audio_file.parent.stem\n",
    "        audio_features = preprocess_wav(audio_file,self.sample_rate)\n",
    "        return audio_features, label\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101,)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = GenderDataset(Path('Dataset'))\n",
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-492.583435</td>\n",
       "      <td>5.590181</td>\n",
       "      <td>-85.012947</td>\n",
       "      <td>-29.718378</td>\n",
       "      <td>13.982943</td>\n",
       "      <td>-15.483821</td>\n",
       "      <td>-1.473186</td>\n",
       "      <td>22.367838</td>\n",
       "      <td>-20.045767</td>\n",
       "      <td>-24.534910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>4517.796986</td>\n",
       "      <td>1258.974650</td>\n",
       "      <td>4421.875</td>\n",
       "      <td>7781.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3843.750</td>\n",
       "      <td>5343.750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-624.739197</td>\n",
       "      <td>41.501122</td>\n",
       "      <td>-72.664757</td>\n",
       "      <td>7.006831</td>\n",
       "      <td>-36.303776</td>\n",
       "      <td>-32.625492</td>\n",
       "      <td>-16.470577</td>\n",
       "      <td>-2.263682</td>\n",
       "      <td>-38.486450</td>\n",
       "      <td>-22.437748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>4062.229671</td>\n",
       "      <td>1837.402135</td>\n",
       "      <td>4046.875</td>\n",
       "      <td>7671.875</td>\n",
       "      <td>671.875</td>\n",
       "      <td>2671.875</td>\n",
       "      <td>5656.250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-888.857483</td>\n",
       "      <td>78.258888</td>\n",
       "      <td>-33.335213</td>\n",
       "      <td>-11.957570</td>\n",
       "      <td>-13.451708</td>\n",
       "      <td>10.004904</td>\n",
       "      <td>-15.609121</td>\n",
       "      <td>-14.173033</td>\n",
       "      <td>-16.972511</td>\n",
       "      <td>3.926111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>3575.753891</td>\n",
       "      <td>1769.505889</td>\n",
       "      <td>3265.625</td>\n",
       "      <td>7265.625</td>\n",
       "      <td>562.500</td>\n",
       "      <td>2218.750</td>\n",
       "      <td>5187.500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-513.988708</td>\n",
       "      <td>38.329533</td>\n",
       "      <td>-84.357986</td>\n",
       "      <td>-54.898586</td>\n",
       "      <td>-18.513611</td>\n",
       "      <td>-20.977715</td>\n",
       "      <td>-33.619297</td>\n",
       "      <td>-1.871510</td>\n",
       "      <td>-2.335996</td>\n",
       "      <td>-15.545382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>4317.977941</td>\n",
       "      <td>1768.822872</td>\n",
       "      <td>3984.375</td>\n",
       "      <td>7765.625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2906.250</td>\n",
       "      <td>5359.375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-449.652100</td>\n",
       "      <td>55.489613</td>\n",
       "      <td>-45.956360</td>\n",
       "      <td>-41.597935</td>\n",
       "      <td>-19.258604</td>\n",
       "      <td>-1.030979</td>\n",
       "      <td>-12.622212</td>\n",
       "      <td>7.296183</td>\n",
       "      <td>-13.935996</td>\n",
       "      <td>-15.501382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>4162.197232</td>\n",
       "      <td>1531.697944</td>\n",
       "      <td>3687.500</td>\n",
       "      <td>7718.750</td>\n",
       "      <td>1046.875</td>\n",
       "      <td>2968.750</td>\n",
       "      <td>5203.125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5  \\\n",
       "0 -492.583435   5.590181 -85.012947 -29.718378  13.982943 -15.483821   \n",
       "1 -624.739197  41.501122 -72.664757   7.006831 -36.303776 -32.625492   \n",
       "2 -888.857483  78.258888 -33.335213 -11.957570 -13.451708  10.004904   \n",
       "3 -513.988708  38.329533 -84.357986 -54.898586 -18.513611 -20.977715   \n",
       "4 -449.652100  55.489613 -45.956360 -41.597935 -19.258604  -1.030979   \n",
       "\n",
       "           6          7          8          9  ...        92        93  \\\n",
       "0  -1.473186  22.367838 -20.045767 -24.534910  ...  0.000040  0.003420   \n",
       "1 -16.470577  -2.263682 -38.486450 -22.437748  ...  0.000046  0.001125   \n",
       "2 -15.609121 -14.173033 -16.972511   3.926111  ...  0.000070  0.013684   \n",
       "3 -33.619297  -1.871510  -2.335996 -15.545382  ...  0.000014  0.002770   \n",
       "4 -12.622212   7.296183 -13.935996 -15.501382  ...  0.000029  0.005256   \n",
       "\n",
       "            94           95        96        97        98        99       100  \\\n",
       "0  4517.796986  1258.974650  4421.875  7781.250     0.000  3843.750  5343.750   \n",
       "1  4062.229671  1837.402135  4046.875  7671.875   671.875  2671.875  5656.250   \n",
       "2  3575.753891  1769.505889  3265.625  7265.625   562.500  2218.750  5187.500   \n",
       "3  4317.977941  1768.822872  3984.375  7765.625     0.000  2906.250  5359.375   \n",
       "4  4162.197232  1531.697944  3687.500  7718.750  1046.875  2968.750  5203.125   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "label_to_num_map = {'males':0,'females':1}\n",
    "num_to_label_map = {0:'males',1:'females'}\n",
    "data=[]\n",
    "labels=[]\n",
    "for i in range(len(dataset)):\n",
    "    features,label = dataset[i]\n",
    "    data.append(features)\n",
    "    labels.append(label_to_num_map[label])\n",
    "df = pd.DataFrame(data)\n",
    "df['label'] = labels\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "series = pd.Series(labels)\n",
    "series.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.astype(str)\n",
    "df.to_csv('data.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def likelihood(x, mean, variance):\n",
    "    return (1 / np.sqrt(2 * np.pi * variance)) * np.exp(-0.5 * ((x - mean) ** 2) / variance)\n",
    "\n",
    "class NaiveBayesClassifier():\n",
    "    def __init__(self):\n",
    "        self.variances= {0:{},1:{}}\n",
    "        self.means= {0:{},1:{}}\n",
    "        self.priors= {0:0,1:0}\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        self.priors[0] = (df[df['label']==0].shape[0]) / df.shape[0]\n",
    "        self.priors[1] = (df[df['label']==1].shape[0]) / df.shape[0]\n",
    "        for i in range(len(df.columns)- 1):\n",
    "            self.variances[0][i] = df[df['label']==0].iloc[:,i].var()\n",
    "            self.variances[1][i] = df[df['label']==1].iloc[:,i].var()\n",
    "            self.means[0][i] = df[df['label']==0].iloc[:,i].mean()\n",
    "            self.means[1][i] = df[df['label']==1].iloc[:,i].mean()\n",
    "    def predict_sample(self,x):\n",
    "        likelihoods = {0:[],1:[]}\n",
    "        for i in range(len(x)):\n",
    "            likelihoods[0].append(likelihood(x[i],self.means[0][i],self.variances[0][i]))\n",
    "            likelihoods[1].append(likelihood(x[i],self.means[1][i],self.variances[1][i]))\n",
    "        posteriors = {0:0,1:0}\n",
    "        for i in range(len(likelihoods[0])):\n",
    "            posteriors[0] += np.log(likelihoods[0][i])\n",
    "            posteriors[1] += np.log(likelihoods[1][i])\n",
    "        posteriors[0] += np.log(self.priors[0])\n",
    "        posteriors[1] += np.log(self.priors[1])\n",
    "        if(posteriors[0] > posteriors[1]):\n",
    "            return 0\n",
    "        return 1\n",
    "    def predict(self,X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            predictions.append(self.predict_sample(x))\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler()\n",
    "df_train, df_test = train_test_split(df,test_size=0.2,random_state=42)\n",
    "y_train = df_train['label'].values\n",
    "X= scaler.fit_transform(df_train.drop(columns=['label']))\n",
    "df_scaled = pd.DataFrame(X,columns=df_train.columns[:-1])\n",
    "df_scaled['label'] = y_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayesClassifier()\n",
    "naive_bayes.fit(df_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(df_test.drop(columns=['label']))\n",
    "y_test = df_test['label']\n",
    "y_pred =naive_bayes.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Scratch Naive-Bayes Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "print(f\"From Scratch Naive-Bayes Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       711\n",
      "           1       0.77      0.77      0.77       488\n",
      "\n",
      "    accuracy                           0.82      1199\n",
      "   macro avg       0.81      0.81      0.81      1199\n",
      "weighted avg       0.82      0.82      0.82      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "individual_naive_report = classification_report(y_test,y_pred)\n",
    "print(individual_naive_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Naive Bayes Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "X_train = df_scaled.drop(columns=['label'])\n",
    "y_train = df_scaled['label']\n",
    "gnb.fit(X_train,y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "print(f\"Sklearn Naive Bayes Accuracy: {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Custom samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished.\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "fs = 44100  \n",
    "duration = 5 \n",
    "\n",
    "print(\"Recording...\")\n",
    "audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16',device=2)\n",
    "sd.wait()  \n",
    "print(\"Recording finished.\")\n",
    "\n",
    "write(\"output.wav\", fs, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Gender: Male\n"
     ]
    }
   ],
   "source": [
    "def predict_custom_sample(wav_path,model):\n",
    "    features = preprocess_wav(wav_path)\n",
    "    features = scaler.transform(features.reshape(1,-1))\n",
    "    output = model.predict_sample(features.flatten())\n",
    "    gender = 'Male' if output == 0 else 'Female'\n",
    "    return gender\n",
    "prediction = predict_custom_sample('output.wav',naive_bayes)\n",
    "\n",
    "print(f\"Predicted Gender: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Bagging ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from scipy.stats import mode\n",
    "\n",
    "def random_subset(X,y=None):\n",
    "    n = X.shape[0]\n",
    "    indices = np.random.choice(n,size=n,replace=True)\n",
    "    if y is not None:\n",
    "        return X[indices], y[indices]\n",
    "    return X.iloc[indices], None\n",
    "    \n",
    "    \n",
    "class BaggingClassifier():\n",
    "    def __init__(self,base_model,n_models):\n",
    "        self.base_model = base_model\n",
    "        self.n_models = n_models\n",
    "        self.models = []\n",
    "    def fit(self,X,y=None):\n",
    "        for i in range(self.n_models):\n",
    "            model = copy.deepcopy(self.base_model)\n",
    "            X_train, y_train = random_subset(X,y)\n",
    "            model.fit(X_train,y_train)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self,X):\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            prediction = model.predict(X)\n",
    "            predictions.append(prediction)\n",
    "        return mode(predictions)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_naive = NaiveBayesClassifier()\n",
    "bagging_naive = BaggingClassifier(base_model=base_naive,n_models=10)\n",
    "bagging_naive.fit(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       711\n",
      "           1       0.78      0.77      0.77       488\n",
      "\n",
      "    accuracy                           0.82      1199\n",
      "   macro avg       0.81      0.81      0.81      1199\n",
      "weighted avg       0.82      0.82      0.82      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_bagging = bagging_naive.predict(X_test)\n",
    "bagging_naive_report = classification_report(y_test,y_pred_bagging)\n",
    "print(bagging_naive_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "bagging_lr = BaggingClassifier(base_model=lr,n_models=10)\n",
    "bagging_lr.fit((df_scaled.drop(columns=['label'])).values,df_scaled['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       711\n",
      "           1       0.89      0.84      0.87       488\n",
      "\n",
      "    accuracy                           0.89      1199\n",
      "   macro avg       0.89      0.89      0.89      1199\n",
      "weighted avg       0.89      0.89      0.89      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_bagging_lr = bagging_lr.predict(X_test)\n",
    "bagging_lr_report = classification_report(y_test,y_pred_bagging_lr)\n",
    "print(bagging_lr_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between different approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       711\n",
      "           1       0.77      0.77      0.77       488\n",
      "\n",
      "    accuracy                           0.82      1199\n",
      "   macro avg       0.81      0.81      0.81      1199\n",
      "weighted avg       0.82      0.82      0.82      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Individual Naive Bayes')\n",
    "print(individual_naive_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       711\n",
      "           1       0.78      0.77      0.77       488\n",
      "\n",
      "    accuracy                           0.82      1199\n",
      "   macro avg       0.81      0.81      0.81      1199\n",
      "weighted avg       0.82      0.82      0.82      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Bagging Naive Bayes')\n",
    "print(bagging_naive_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       711\n",
      "           1       0.89      0.84      0.87       488\n",
      "\n",
      "    accuracy                           0.89      1199\n",
      "   macro avg       0.89      0.89      0.89      1199\n",
      "weighted avg       0.89      0.89      0.89      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Bagging Logistic Regression')\n",
    "print(bagging_lr_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
